{
  "lines_of_code": 18,
  "char_count": 667,
  "function_count": 1,
  "class_count": 1,
  "if_count": 2,
  "loop_count": 5,
  "exception_count": 0,
  "import_count": 0,
  "docstring_count": 0,
  "avg_method_length": 5.0,
  "max_method_length": 5,
  "min_method_length": 5,
  "avg_cyclomatic_complexity": 9.5,
  "max_cyclomatic_complexity": 10,
  "raw_loc": 18,
  "raw_lloc": 18,
  "raw_sloc": 18,
  "raw_comments": 0,
  "raw_multi": 0,
  "raw_blank": 0,
  "raw_single_comments": 0,
  "radon_halstead_error": "'Halstead' object has no attribute 'h1'",
  "pylint_score": 4.44,
  "pylint_errors": 0,
  "pylint_warnings": 0,
  "pylint_conventions": 0,
  "pylint_refactors": 0,
  "pylint_issue_count": 0,
  "lizard_error": "'FunctionInfo' object has no attribute 'cognitive_complexity'",
  "cognitive_complexity": -1,
  "max_line_length": 82,
  "avg_line_length": 36.111111111111114,
  "comment_count": 0,
  "comment_ratio": 0.0,
  "problem_id": "3317",
  "problem_title": "maximum-palindromes-after-operations",
  "solution_idx": 2,
  "graded": false,
  "error_code": -2.0,
  "error_message": "Wrong Answer",
  "execution_time": NaN,
  "difficulty": "medium",
  "platform": "leetcode",
  "tone_category": "ingratiating",
  "model_name": "LLama3-70b-8192-Groq",
  "pass_at_1": 0.0,
  "max_cognitive_complexity": NaN,
  "avg_cognitive_complexity": NaN,
  "avg_nloc": NaN,
  "max_nloc": NaN
}