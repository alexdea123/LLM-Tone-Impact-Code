# LLM-Tone-Impact-Code
RQ1: Does varying the politeness or influence tactic (e.g., polite request vs. threat vs. flattery) in prompts significantly affect the correctness and quality of code generated by large language models?
RQ2: Which of Yuklâ€™s categories of influence (e.g., pressure tactics, inspirational appeals, reciprocity) produce the most notable changes in code performance, structure, and complexity?
RQ3: Which code-quality metrics (e.g., lines of code, cyclomatic complexity) best capture differences arising from varied prompt framing?


In a new conda environment (python=3.13), run:

```
pip install radon pylint groq pandas tqdm
```